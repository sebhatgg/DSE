{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09e23a9",
   "metadata": {},
   "source": [
    "##### The creation of a hybrid anomaly detection model starts by preparing the dataset. Then, choose important features and divide the data for training and testing. Utilize a sparse autoencoder to simplify the input space. Normalize features with feature scaling. Next, SVM will be used for precise classification, and Isolation Forest will be used for outlier detection. Assess model performance with various metrics. This method combines different models for efficient anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf01a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d477d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 13)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27508\\2708595114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mcomplete_anomaly_detection_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27508\\2708595114.py\u001b[0m in \u001b[0;36mcomplete_anomaly_detection_system\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mautoencoder_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mautoencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mautoencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Get the encoded representation of the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sebha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 13)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, regularizers\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def complete_anomaly_detection_system():\n",
    "    \n",
    "    # Load data from a CSV file   \n",
    "    data = pd.read_csv('adultdata.csv')\n",
    "    \n",
    "    #convert all the values in the columns into numeric\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in data.select_dtypes(include=['object']).columns:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "    \n",
    "    data = data.drop('Sex', axis=1)\n",
    "    \n",
    "    X = data.drop('fnlwgt', axis=1)  # Assuming 'target' is the column name of the continuous target variable\n",
    "    y_cont = data['fnlwgt']\n",
    "    \n",
    "    y = np.where(y_cont > 80000, 1, 0)  # Define `threshold` based on your domain knowledge\n",
    "    \n",
    "    # Select top k features; k might be adjusted based on the dataset\n",
    "    selector = SelectKBest(f_classif, k=10)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    #data.info()\n",
    "\n",
    "\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Build a sparse autoencoder\n",
    "    # Sparse Autoencoder\n",
    "    input_dim = X_selected.shape[1]\n",
    "    encoding_dim = 5  # You can adjust the encoding dimension as needed\n",
    "    input_data = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_data)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    autoencoder_model = Model(input_data, decoded)\n",
    "    autoencoder_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    autoencoder_model.fit(X, X, epochs=50, batch_size=32, shuffle=True, validation_split=0.2)\n",
    "\n",
    "    # Get the encoded representation of the data\n",
    "    encoded_data = autoencoder_model.predict(X)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(encoded_data, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train SVM on the encoded data\n",
    "    svm = SVC(kernel='rbf', gamma='auto', class_weight='balanced', random_state=42)\n",
    "    svm.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Predict with SVM\n",
    "    svm_predictions_train = svm.predict(X_train_encoded)\n",
    "    \n",
    "    # Filter only rows SVM detected as normal\n",
    "    normal_indices_train = svm_predictions_train == 1\n",
    "    X_train_normal = X_train_encoded[normal_indices_train]\n",
    "    \n",
    "    # Train Isolation Forest on the filtered normal data\n",
    "    iso_forest = IsolationForest(random_state=42)\n",
    "    iso_forest.fit(X_train_normal)\n",
    "    \n",
    "    # Predict on the test data with Isolation Forest\n",
    "    if_predictions = iso_forest.predict(X_test_encoded)\n",
    "    if_predictions = np.where(if_predictions == 1, 1, 0)  # Convert -1, 1 to 0, 1\n",
    "    \n",
    "    # Evaluate the model\n",
    "    precision = precision_score(y_test, if_predictions, pos_label=0)\n",
    "    recall = recall_score(y_test, if_predictions, pos_label=0)\n",
    "    f1 = f1_score(y_test, if_predictions, pos_label=0)\n",
    "    \n",
    "    print(classification_report(y_test, if_predictions))\n",
    "    \n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    cm = confusion_matrix(y_test, if_predictions, labels=[0, 1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Anomaly', 'Normal'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "complete_anomaly_detection_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9735a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
