{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3970a6a9",
   "metadata": {},
   "source": [
    "##### To develop a hybrid anomaly detection model using a sparse autoencoder, Isolation Forest, and XGBoost in sequence, begin by loading and cleaning your data. Select important features and split the dataset into training and testing sets. Normalize these features through feature scaling. Use a sparse autoencoder to reduce the dimensionality of your data, enhancing manageability and focus. Apply an Isolation Forest to effectively identify initial anomalies, and then refine the detection with XGBoost, a powerful classifier that improves the model's sensitivity and accuracy. Evaluate the model's performance using precision, recall, F1-score, and a confusion matrix. This approach combines the strengths of dimensionality reduction, anomaly isolation, and advanced classification to effectively detect anomalies in diverse data scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1df336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c68ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_anomaly_detection_system():\n",
    "    # Load and preprocess data\n",
    "    data = pd.read_csv('adultdata.csv')\n",
    "    \n",
    "    #convert all the values in the columns into numeric\n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in data.select_dtypes(include=['object']).columns:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "    \n",
    "    data = data.drop('Sex', axis=1)\n",
    "    \n",
    "    X = data.drop('fnlwgt', axis=1)  # Assuming 'target' is the column name of the continuous target variable\n",
    "    y_cont = data['fnlwgt']\n",
    "    \n",
    "    y = np.where(y_cont > 80000, 1, 0)  # Define `threshold` based on your domain knowledge\n",
    "    \n",
    "    # Select top k features; k might be adjusted based on the dataset\n",
    "    selector = SelectKBest(f_classif, k=10)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    #data.info()\n",
    "\n",
    "\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Define and train the autoencoder\n",
    "    input_dim = X_scaled.shape[1]\n",
    "    encoding_dim = 32\n",
    "    input_layer = tf.keras.Input(shape=(input_dim,))\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu', \n",
    "                           activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    autoencoder = models.Model(input_layer, decoded)\n",
    "    encoder = models.Model(input_layer, encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.1, verbose=1)\n",
    "\n",
    "    # Encode the data\n",
    "    X_train_encoded = encoder.predict(X_train)\n",
    "    X_test_encoded = encoder.predict(X_test)\n",
    "    \n",
    "    # Train XGBoost on the encoded data\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Predict with XGBoost to filter normal data\n",
    "    xgb_predictions_train = xgb.predict(X_train_encoded)\n",
    "    normal_indices = (xgb_predictions_train == 1)\n",
    "    X_train_normal = X_train_encoded[normal_indices]\n",
    "    \n",
    "    # Train Isolation Forest on the filtered normal data\n",
    "    iso_forest = IsolationForest(random_state=42)\n",
    "    iso_forest.fit(X_train_normal)\n",
    "    \n",
    "    # Predict on the entire test dataset with Isolation Forest\n",
    "    if_predictions = iso_forest.predict(X_test_encoded)\n",
    "    if_predictions = np.where(if_predictions == 1, 1, 0)  # Convert predictions to binary\n",
    "    \n",
    "    # Evaluate the model\n",
    "    precision = precision_score(y_test, if_predictions, pos_label=0)\n",
    "    recall = recall_score(y_test, if_predictions, pos_label=0)\n",
    "    f1 = f1_score(y_test, if_predictions, pos_label=0)\n",
    "    \n",
    "    \n",
    "    print(classification_report(y_test, if_predictions))\n",
    "    \n",
    "\n",
    "    # Output the metrics\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    cm = confusion_matrix(y_test, if_predictions, labels=[0, 1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Anomaly', 'Normal'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Ensure your CSV file is at the specified path and correctly formatted\n",
    "complete_anomaly_detection_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5fa31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
